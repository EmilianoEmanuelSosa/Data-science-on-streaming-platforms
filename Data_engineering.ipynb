{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"AA3ZkaHCDK2U"},"source":["-- Importo la librería de pandas, numpy y matoplotlib (imagenes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4BDRTbesDQf0"},"outputs":[],"source":["import pandas as pd"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"k3Uvlvd3DfVb"},"source":["Descargo los csv en formato pandas, para análisis de datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9658rHPDk6l"},"outputs":[],"source":["dfAmazon = pd.read_csv('datasets/amazon_prime_titles.csv', encoding = 'utf-8')\n","dfDisney = pd.read_csv('datasets/disney_plus_titles.csv', encoding='utf-8')\n","dfHuluTitles = pd.read_csv('datasets/hulu_titles.csv', encoding='utf-8')\n","dfNetflix = pd.read_csv('datasets/netflix_titles.csv', encoding='utf-8')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7FSTcBbmDDMm"},"source":["**TRATAMIENTO DE DATOS**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"R865lCBFUuq2"},"source":["*Evaluacion de nulos por dataframe*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ganxu7ueMmKn"},"outputs":[],"source":["dfAmazon.isnull().sum()\n","#dfAmazon.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n3HugHpbQzBp"},"outputs":[],"source":["dfDisney.isnull().sum()\n","#dfDisney.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZrbaxgZxR6Og"},"outputs":[],"source":["dfHuluTitles.isnull().sum()\n","#dfHuluTitles.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QGn5Zy9GUZ5r"},"outputs":[],"source":["dfNetflix.isnull().sum()\n","#dfNetflix.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7clMDWBEU3wj"},"source":["----"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"OiEJ3MA0CuK9"},"source":["Agregamos la primera letra de la plataforma a cada uno de los ID de la columna *show_id*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kmajlAWJU5RR"},"outputs":[],"source":["string_agregar='a'\n","dfAmazon['show_id']=dfAmazon['show_id'].apply(lambda x: string_agregar + x) #aplicamos una funcion lambda dentro de un aplly \n","                                                                            #por sobre toda la columnas\n","string_agregar='d'\n","dfDisney['show_id']=dfDisney['show_id'].apply(lambda x: string_agregar + x)\n","\n","string_agregar='h'\n","dfHuluTitles['show_id']=dfHuluTitles['show_id'].apply(lambda x: string_agregar + x)\n","\n","string_agregar='n'\n","dfNetflix['show_id']=dfNetflix['show_id'].apply(lambda x: string_agregar + x)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bYYRmc1jJbt0"},"source":["---"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0LhLeCJcDXBB"},"source":["Todos los valores nulos de la columna *rating* se les agrega el string *G* como apto para todas las audiencias"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l2KYB1MtDJ3e"},"outputs":[],"source":["value='g'\n","dfAmazon['rating']=dfAmazon['rating'].fillna(value)\n","#dfAmazon['rating'].unique()\n","\n","value='g'\n","dfDisney['rating']=dfDisney['rating'].fillna(value)\n","\n","value='g'\n","dfHuluTitles['rating']=dfHuluTitles['rating'].fillna(value)\n","\n","value='g'\n","dfNetflix['rating']=dfNetflix['rating'].fillna(value)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"g13tUzC5JiKb"},"source":["---"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BTBqI2NlFb6P"},"source":["Todos los strings se pasan a *minuscula*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"edRmN7FVFbUu"},"outputs":[],"source":["dfAmazon = dfAmazon.applymap(lambda x: x.lower() if isinstance(x, str) else x)  #aplicamos una funcion lambda dentro de un applymap \n","                                                                                #para pueda diferenciar entre str e int\n","dfDisney = dfDisney.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n","\n","dfHuluTitles = dfHuluTitles.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n","\n","dfNetflix = dfNetflix.applymap(lambda x: x.lower() if isinstance(x, str) else x)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"UTBmRoYTJjd4"},"source":["---"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-Ti8eou6I1mc"},"source":["Dividimos el camp *duration* en dos **(duration_int y duration_type)**, el primero será un integer y el segundo un string indicando la unidad de medición de duración: min (minutos) o season (temporadas)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fQ2vK82cNK2N"},"outputs":[],"source":["dfAmazon.loc[dfAmazon['type'] == 'movie', 'duration_int'] = dfAmazon['duration'].str.split(' ').str[0]\n","dfAmazon.loc[dfAmazon['type'] == 'tv show', 'duration_int'] = dfAmazon['duration'].str.split(' ').str[0]\n","dfAmazon.loc[dfAmazon['type']=='movie','duration_type']='min'\n","dfAmazon.loc[dfAmazon['type']=='tv show','duration_type']='season'\n","dfAmazon['duration_int'] = dfAmazon['duration_int'].fillna(0)\n","dfAmazon['duration_int'] = dfAmazon['duration_int'].astype(int)\n","\n","dfDisney.loc[dfDisney['type'] == 'movie', 'duration_int'] = dfDisney['duration'].str.split(' ').str[0]\n","dfDisney.loc[dfDisney['type'] == 'tv show', 'duration_int'] = dfDisney['duration'].str.split(' ').str[0]\n","dfDisney.loc[dfDisney['type']=='movie','duration_type']='min'\n","dfDisney.loc[dfDisney['type']=='tv show','duration_type']='season'\n","dfDisney['duration_int'] = dfDisney['duration_int'].fillna(0)\n","dfDisney['duration_int'] = dfDisney['duration_int'].astype(int)\n","\n","dfHuluTitles.loc[dfHuluTitles['type'] == 'movie', 'duration_int'] = dfHuluTitles['duration'].str.split(' ').str[0]\n","dfHuluTitles.loc[dfHuluTitles['type'] == 'tv show', 'duration_int'] = dfHuluTitles['duration'].str.split(' ').str[0]\n","dfHuluTitles.loc[dfHuluTitles['type']=='movie','duration_type']='min'\n","dfHuluTitles.loc[dfHuluTitles['type']=='tv show','duration_type']='season'\n","dfHuluTitles['duration_int'] = dfHuluTitles['duration_int'].fillna(0)\n","dfHuluTitles['duration_int'] = dfHuluTitles['duration_int'].astype(int)\n","\n","dfNetflix.loc[dfNetflix['type'] == 'movie', 'duration_int'] = dfNetflix['duration'].str.split(' ').str[0]\n","dfNetflix.loc[dfNetflix['type'] == 'tv show', 'duration_int'] = dfNetflix['duration'].str.split(' ').str[0]\n","dfNetflix.loc[dfNetflix['type']=='movie','duration_type']='min'\n","dfNetflix.loc[dfNetflix['type']=='tv show','duration_type']='season'\n","dfNetflix['duration_int'] = dfNetflix['duration_int'].fillna(0)\n","dfNetflix['duration_int'] = dfNetflix['duration_int'].astype(int)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"KkU60L6ufMU0"},"source":["Quitamos *duration* y reordenamos las columnas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84MCvv29dr6b"},"outputs":[],"source":["dfAmazon = dfAmazon.drop(columns = ['duration'])\n","\n","dfDisney = dfDisney.drop(columns = ['duration'])\n","\n","dfHuluTitles = dfHuluTitles.drop(columns = ['duration'])\n","\n","dfNetflix = dfNetflix.drop(columns = ['duration'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4VtxZmYNJTMe"},"outputs":[],"source":["dfAmazon = dfAmazon.reindex(columns=['show_id','type','title','director','cast','country','release_year','rating','duration_int','duration_type','listed_in'])\n","\n","dfDisney = dfDisney.reindex(columns=['show_id','type','title','director','cast','country','release_year','rating','duration_int','duration_type','listed_in'])\n","\n","dfHuluTitles = dfHuluTitles.reindex(columns=['show_id','type','title','director','cast','country','release_year','rating','duration_int','duration_type','listed_in'])\n","\n","dfNetflix = dfNetflix.reindex(columns=['show_id','type','title','director','cast','country','release_year','rating','duration_int','duration_type','listed_in'])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zgvK7ePelmkS"},"source":["---"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ar09BfDzp6am"},"source":["Calculamos el promedio de duracion filtrando por tipo, para rellenar los valores nulos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":249,"status":"ok","timestamp":1684629068926,"user":{"displayName":"Allan Tilca","userId":"08979892714624010949"},"user_tz":180},"id":"junZx3MepfTX","outputId":"ae6cec7b-6a41-4ad7-b8d1-53aeb9a8f8e9"},"outputs":[],"source":["dfAmazon[dfAmazon['duration_int'] != 0].groupby('type')['duration_int'].mean()  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pnl1A2UJtcgV"},"outputs":[],"source":["dfDisney[dfDisney['duration_int'] != 0].groupby('type')['duration_int'].mean()  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PTBaB4AitcwQ"},"outputs":[],"source":["dfHuluTitles[dfHuluTitles['duration_int'] != 0].groupby('type')['duration_int'].mean()  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5afQff-wtc5c"},"outputs":[],"source":["dfNetflix[dfNetflix['duration_int'] != 0].groupby('type')['duration_int'].mean()  "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xXoeoyhEssZ6"},"source":["Llenamos los valores nulos(que eran igual a 0) con el promedio obtenido anteriormente "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iuERZ4oHrHuk"},"outputs":[],"source":["dfAmazon.loc[dfAmazon['type'] == 'movie', 'duration_int'] = dfAmazon.loc[dfAmazon['type'] == 'movie', 'duration_int'].replace(0, 92)\n","dfAmazon.loc[dfAmazon['type'] == 'tv show', 'duration_int'] = dfAmazon.loc[dfAmazon['type'] == 'tv show', 'duration_int'].replace(0, 2)\n","\n","dfDisney.loc[dfDisney['type'] == 'movie', 'duration_int'] = dfDisney.loc[dfDisney['type'] == 'movie', 'duration_int'].replace(0, 72)\n","dfDisney.loc[dfDisney['type'] == 'tv show', 'duration_int'] = dfDisney.loc[dfDisney['type'] == 'tv show', 'duration_int'].replace(0, 2)\n","\n","dfHuluTitles.loc[dfHuluTitles['type'] == 'movie', 'duration_int'] = dfHuluTitles.loc[dfHuluTitles['type'] == 'movie', 'duration_int'].replace(0,98 )\n","dfHuluTitles.loc[dfHuluTitles['type'] == 'tv show', 'duration_int'] = dfHuluTitles.loc[dfHuluTitles['type'] == 'tv show', 'duration_int'].replace(0, 3)\n","\n","dfNetflix.loc[dfNetflix['type'] == 'movie', 'duration_int'] = dfNetflix.loc[dfNetflix['type'] == 'movie', 'duration_int'].replace(0, 99)\n","dfNetflix.loc[dfNetflix['type'] == 'tv show', 'duration_int'] = dfNetflix.loc[dfNetflix['type'] == 'tv show', 'duration_int'].replace(0, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfAmazon.columns"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Se descargan los archivos de csv_rating para la obtención del puntaje y posterior análisis de machine learning"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfCsv1 = pd.read_csv('ratings/1.csv', encoding = 'utf-8')\n","dfCsv2 = pd.read_csv('ratings/2.csv', encoding = 'utf-8')\n","dfCsv3 = pd.read_csv('ratings/3.csv', encoding = 'utf-8')\n","dfCsv4 = pd.read_csv('ratings/4.csv', encoding = 'utf-8')\n","dfCsv5 = pd.read_csv('ratings/5.csv', encoding = 'utf-8')\n","dfCsv6 = pd.read_csv('ratings/6.csv', encoding = 'utf-8')\n","dfCsv7 = pd.read_csv('ratings/7.csv', encoding = 'utf-8')\n","dfCsv8 = pd.read_csv('ratings/8.csv', encoding = 'utf-8')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Verifico los nombres de las columnas\n","dfCsv1.head(3)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Se agrupan los Id de Película con el Rating para cada uno de los CSV"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfCsv1_promedio= dfCsv1.groupby('movieId')['rating'].mean()\n","dfCsv2_promedio= dfCsv2.groupby('movieId')['rating'].mean()\n","dfCsv3_promedio= dfCsv3.groupby('movieId')['rating'].mean()\n","dfCsv4_promedio= dfCsv4.groupby('movieId')['rating'].mean()\n","dfCsv5_promedio= dfCsv5.groupby('movieId')['rating'].mean()\n","dfCsv6_promedio= dfCsv6.groupby('movieId')['rating'].mean()\n","dfCsv7_promedio= dfCsv7.groupby('movieId')['rating'].mean()\n","dfCsv8_promedio= dfCsv8.groupby('movieId')['rating'].mean()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Procedemos a confirmar si hay datos coincidentes en moviedId entre los DF"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Se unen los DF para evaluar correlación, se realiza por parte considerando que no se permite unir varios DF \n","CorrelaciónDF1y2 = pd.merge(dfCsv1_promedio, dfCsv2_promedio, on='movieId', how='inner')\n","CorrelaciónDF3y4 = pd.merge(dfCsv3_promedio, dfCsv4_promedio, on='movieId', how='inner')\n","CorrelaciónDF5y6 = pd.merge(dfCsv5_promedio, dfCsv6_promedio, on='movieId', how='inner')\n","CorrelaciónDF7y8 = pd.merge(dfCsv7_promedio, dfCsv8_promedio, on='movieId', how='inner')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Se agrupa por df hasta obtener la correlación final, esto debido a que pandas no permite unir más de dos DF\n","CorrelaciónDF1_4 = pd.merge(CorrelaciónDF1y2, CorrelaciónDF3y4, on='movieId', how='inner' )\n","CorrelaciónDF5_8 = pd.merge(CorrelaciónDF5y6,CorrelaciónDF7y8, on='movieId', how='inner') \n","CorrelaciónFinal = pd.merge(CorrelaciónDF1_4, CorrelaciónDF5_8, on='movieId', how='inner')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["CorrelaciónFinal.head(2)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Como los datos están agrupados en varias columnas genero un promedio entre ellas para agruparlas y poderlas \n","posteriormente subir a una unica columna"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Primero coloco todas con el nombre rating para poder filtrar por columna y sacar el promedio\n","CorrelaciónFinal.rename(columns={'rating_x_x_x': 'rating', 'rating_y_x_x': 'rating', 'rating_x_y_x': 'rating', 'rating_y_y_x': 'rating', 'rating_x_x_y': 'rating', 'rating_y_x_y': 'rating', 'rating_x_y_y': 'rating', 'rating_y_y_y': 'rating'}, inplace=True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Saco el promedio para ello filtro por fila con la funcion filter en opción rating y que se aplique a las filas\n","CorrelaciónFinal['Promedio'] = CorrelaciónFinal.filter(like='rating').mean(axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["CorrelaciónFinal.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Creo una variable para identificar todas las filas que tengan la opción para posteriormente eliminarlas\n","EliminarColumnas = CorrelaciónFinal.columns[0:7]\n","#Elimino las filas innecesarias y me quedo solo con el promedio\n","CorrelaciónFinal = CorrelaciónFinal.drop(EliminarColumnas, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Garantizo que me quedé solo con la columna promedio\n","CorrelaciónFinal.columns"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Dado que está organizado las columnas se reorganizan los indices, y se renombran las columnas para hacer la posterior\n","indexación."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Reorganizo el índice de columnas, dado que movieId no salía como columna\n","CorrelaciónFinal = CorrelaciónFinal.reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["CorrelaciónFinal.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["CorrelaciónFinal.rename(columns={'Promedio':'puntuation', 'movieId': 'show_id'}, inplace=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["CorrelaciónFinal.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfAmazon.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Creo la columna puntuation para cada df para poder posteriormente hacer la correlación\n","dfAmazon['puntuation'] = 0.0\n","dfDisney['puntuation'] = 0.0\n","dfHuluTitles['puntuation'] = 0.0\n","dfNetflix['puntuation'] = 0.0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfAmazon.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(dfAmazon['show_id'].dtype)\n","print(dfDisney['show_id'].dtype)\n","print(dfHuluTitles['show_id'].dtype)\n","print(dfNetflix['show_id'].dtype)\n","print(CorrelaciónFinal['show_id'].dtype)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(dfAmazon['show_id'].duplicated().sum())\n","print(dfDisney['show_id'].duplicated().sum())\n","print(dfHuluTitles['show_id'].duplicated().sum())\n","print(dfNetflix['show_id'].duplicated().sum())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Genero la unión a partir de la función merge por medio de show_id con inner para que solo se una donde haya coincidencias de id\n","dfAmazon = pd.merge(CorrelaciónFinal, dfAmazon, on='show_id', how='inner')\n","dfAmazon['puntuation_y'] = dfAmazon['puntuation_x']\n","\n","dfDisney = pd.merge(CorrelaciónFinal, dfDisney, on='show_id', how='inner')\n","dfDisney['puntuation_y'] = dfDisney['puntuation_x']\n","\n","dfHuluTitles = pd.merge(CorrelaciónFinal, dfHuluTitles, on='show_id', how='inner')\n","dfHuluTitles['puntuation_y'] = dfHuluTitles['puntuation_x']\n","\n","dfNetflix = pd.merge(CorrelaciónFinal, dfNetflix, on='show_id', how='inner')\n","dfNetflix['puntuation_y'] = dfNetflix['puntuation_x']\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfAmazon = dfAmazon.rename(columns={'puntuation_x': 'punctuation'})\n","dfDisney = dfDisney.rename(columns={'puntuation_x': 'punctuation'})\n","dfHuluTitles = dfHuluTitles.rename(columns={'puntuation_x': 'punctuation'})\n","dfNetflix = dfNetflix.rename(columns={'puntuation_x': 'punctuation'})\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfAmazon.drop('puntuation_y', axis=1, inplace=True)\n","dfDisney.drop('puntuation_y', axis=1, inplace=True)\n","dfHuluTitles.drop('puntuation_y', axis=1, inplace=True)\n","dfNetflix.drop('puntuation_y', axis=1, inplace=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Preparo los datos para sacar los outliers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Importo la libería matplotlib para generar gráficos\n","import matplotlib.pyplot as plt"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Concateno los DF para iniciar el calculo de outliers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_combinado = pd.concat([dfAmazon, dfDisney, dfHuluTitles, dfNetflix])  # Concatenar los DataFrames\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_combinado['punctuation'] = df_combinado['punctuation'].round(1)  #redondeamos las puntuaciones"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.title('Histograma de Puntuation')\n","plt.hist (df_combinado['punctuation'], edgecolor = 'black', color = 'aqua', linewidth = 0.8)\n","plt.show"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.title('Histograma de duration_int')\n","plt.hist (df_combinado['duration_int'], edgecolor = 'black', color = 'aqua', linewidth = 0.8)\n","plt.show"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.title('Histograma de release_year')\n","plt.hist (df_combinado['release_year'], edgecolor = 'black', color = 'aqua', linewidth = 0.8)\n","plt.show"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Procedo a calcular la desviación estándar y la media para las columnas \"puntuation\", \"duration_int\" y \"release_year\"\n","Media = df_combinado[['punctuation', 'duration_int', 'release_year']].mean()\n","DesviaciónEstandar = df_combinado[['punctuation', 'duration_int', 'release_year']].std()\n","\n","# Defino los límites superior e inferior\n","LimiteSuperior = Media + 3 * DesviaciónEstandar\n","LimiteInferior = Media - 3 * DesviaciónEstandar\n","\n","# Se identifican los outliers para las columnas \"puntuation\", \"duration_int\" y \"release_year\"\n","outlier = df_combinado[(df_combinado['punctuation'] > LimiteSuperior['punctuation']) | (df_combinado['punctuation'] < LimiteInferior['punctuation']) | \n","                                 (df_combinado['duration_int'] > LimiteSuperior['duration_int']) | (df_combinado['duration_int'] < LimiteInferior['duration_int']) |\n","                                 (df_combinado['release_year'] > LimiteSuperior['release_year']) | (df_combinado['release_year'] < LimiteInferior['release_year'])]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["outlier.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Para hacer más intuitivo la visualización de outliers en este caso se realiza un boxplot\n","plt.boxplot(outlier ['punctuation'], vert=True, showfliers=True)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.boxplot(outlier ['duration_int'], vert=True, showfliers=True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.boxplot(outlier ['release_year'], vert=True, showfliers=True)\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Guardamos el archivo que contiene todos los registros dentro de un csv."]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["df_combinado.to_csv('datasets_norm/registros_peliculas.csv', index=False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
