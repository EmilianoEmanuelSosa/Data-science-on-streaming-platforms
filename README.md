<p align=center><img src=https://d31uz8lwfmyn8g.cloudfront.net/Assets/logo-henry-white-lg.png><p>


# <h1 align=center>**`Machine Learning Operations (MLOps)`**</h1>

<p align="center">
<img src="https://user-images.githubusercontent.com/67664604/217914153-1eb00e25-ac08-4dfa-aaf8-53c09038f082.png"  height=300>
</p>

¬°Bienvenidos al primer proyecto individual de la etapa de labs! En esta ocasi√≥n, deber√°n hacer un trabajo situ√°ndose en el rol de un ***MLOps Engineer***.  

<hr>  

## **Descripci√≥n del problema (Contexto y rol a desarrollar)**

## Contexto

Tienes tu modelo de recomendaci√≥n entrenado dando unas buenas m√©tricas :smirk:, y ahora, c√≥mo lo llevas al mundo real? :eyes:

El ciclo de vida de un proyecto de Machine Learning debe contemplar desde el tratamiento y recolecci√≥n de los datos (Data Engineer stuff) hasta el entrenamiento y mantenimiento del modelo de ML seg√∫n llegan nuevos datos.


## Rol a desarrollar

Empezaste a trabajar como **`Data Scientist`** en una start-up que provee servicios de agregaci√≥n de plataformas de streaming. El mundo es bello y vas a crear tu primer modelo de ML que soluciona un problema de negocio: un sistema de recomendaci√≥n que a√∫n no ha sido puesto en marcha! 

Vas a sus datos y te das cuenta que la madurez de los mismos es poca (ok, es nula :sob:): Datos sin transformar, no hay procesos automatizados para la actualizaci√≥n de nuevas pel√≠culas o series, entre otras cosas‚Ä¶.  haciendo tu trabajo imposible :weary:. 

Debes empezar desde 0, haciendo un trabajo r√°pido de **`Data Engineer`** y tener un **`MVP`** (_Minimum Viable Product_) para la pr√≥xima semana! Tu cabeza va a explotar ü§Ø, pero al menos sabes cual es, conceptualmente, el camino que debes de seguir :exclamation:. As√≠ que te espantas los miedos y te pones manos a la obra :muscle:

<p align="center">
<img src="https://github.com/HX-PRomero/PI_ML_OPS/raw/main/src/DiagramaConceptualDelFlujoDeProcesos.png"  height=500>
</p>

<sub> Nota que aqui se reflejan procesos no herramientas tecnologicas. Has el ejercicio de entender cual herramienta del stack corresponde a cual parte del proceso<sub/>

## **Propuesta de trabajo (requerimientos de aprobaci√≥n)**

**`Transformaciones`**:  Para este MVP no necesitas perfecci√≥n, ¬°necesitas rapidez! ‚è© Vas a hacer estas, ***y solo estas***, transformaciones a los datos:


+ Generar campo **`id`**: Cada id se compondr√° de la primera letra del nombre de la plataforma, seguido del show_id ya presente en los datasets (ejemplo para t√≠tulos de Amazon = **`as123`**)

+ Los valores nulos del campo rating deber√°n reemplazarse por el string ‚Äú**`G`**‚Äù (corresponde al maturity rating: ‚Äúgeneral for all audiences‚Äù

+ De haber fechas, deber√°n tener el formato **`AAAA-mm-dd`**

+ Los campos de texto deber√°n estar en **min√∫sculas**, sin excepciones

+ El campo ***duration*** debe convertirse en dos campos: **`duration_int`** y **`duration_type`**. El primero ser√° un integer y el segundo un string indicando la unidad de medici√≥n de duraci√≥n: min (minutos) o season (temporadas)

<br/>

**`Desarrollo API`**:   Propones disponibilizar los datos de la empresa usando el framework ***FastAPI***, generando diferentes endpoints que se consumiran en la API.

Creas 6 funciones (recuerda que deben tener un decorador por cada una (@app.get(‚Äò/‚Äô)):

+ Pel√≠cula (s√≥lo pel√≠cula, no serie, etc) con mayor duraci√≥n seg√∫n a√±o, plataforma y tipo de duraci√≥n. La funci√≥n debe llamarse get_max_duration(year, platform, duration_type) y debe devolver s√≥lo el string del nombre de la pel√≠cula.
+ Cantidad de pel√≠culas (s√≥lo pel√≠culas, no series, etc) seg√∫n plataforma, con un puntaje mayor a XX en determinado a√±o. La funci√≥n debe llamarse get_score_count(platform, scored, year) y debe devolver un int, con el total de pel√≠culas que cumplen lo solicitado.

+ Cantidad de pel√≠culas (s√≥lo pel√≠culas, no series, etc) seg√∫n plataforma. La funci√≥n debe llamarse get_count_platform(platform) y debe devolver un int, con el n√∫mero total de pel√≠culas de esa plataforma. Las plataformas deben llamarse amazon, netflix, hulu, disney.

+ Actor que m√°s se repite seg√∫n plataforma y a√±o. La funci√≥n debe llamarse get_actor(platform, year) y debe devolver s√≥lo el string con el nombre del actor que m√°s se repite seg√∫n la plataforma y el a√±o dado.

+ La cantidad de contenidos/productos (todo lo disponible en streaming) que se public√≥ por pa√≠s y a√±o. La funci√≥n debe llamarse prod_per_county(tipo,pais,anio) deberia devolver el tipo de contenido (pelicula,serie) por pais y a√±o en un diccionario con las variables llamadas 'pais' (nombre del pais), 'anio' (a√±o), 'pelicula' (tipo de contenido).

+ La cantidad total de contenidos/productos (todo lo disponible en streaming, series, peliculas, etc) seg√∫n el rating de audiencia dado (para que publico fue clasificada la pelicula). La funci√≥n debe llamarse get_contents(rating) y debe devolver el numero total de contenido con ese rating de audiencias.



<br/>


**`Deployment`**: Conoces sobre [Render](https://render.com/docs/free#free-web-services) y tienes un [tutorial de Render](https://github.com/HX-FNegrete/render-fastapi-tutorial) que te hace la vida mas facil :smile: . Tambien podrias usar [Railway](https://railway.app/), pero ten en cuenta que con este si necesitas dockerizacion.

<br/>

**`An√°lisis exploratorio de los datos`**: _(Exploratory Data Analysis-EDA)_

Ya los datos est√°n limpios, ahora es tiempo de investigar las relaciones que hay entre las variables de los datasets, ver si hay outliers o anomal√≠as (que no tienen que ser errores necesariamente :eyes: ), y ver si hay alg√∫n patr√≥n interesante que valga la pena explorar en un an√°lisis posterior.  Sabes que puedes apoyarte en librer√≠as como _pandas profiling, sweetviz, autoviz_, entre otros y sacar de all√≠ tus conclusiones üòâ

**`Sistema de recomendaci√≥n`**: 

Una vez que toda la data es consumible por la API, est√° lista para consumir por los departamentos de Analytics y Machine Learning, y nuestro EDA nos permite entender bien los datos a los que tenemos acceso, es hora de entrenar nuestro modelo de machine learning para armar un sistema de recomendaci√≥n de pel√≠culas. √âste consiste en recomendar pel√≠culas a los usuarios bas√°ndose en pel√≠culas similares, por lo que se debe encontrar la similitud de puntuaci√≥n entre esa pel√≠cula y el resto de pel√≠culas, se ordenar√°n seg√∫n el score y devolver√° una lista de Python con 5 valores, cada uno siendo el string del nombre de las pel√≠culas con mayor puntaje, en orden descendente. Debe ser deployado como una funci√≥n adicional de la API anterior y debe llamarse get_recommendation(titulo: str).

<br/>

**`Video`**: Necesitas que al equipo le quede claro que tus herramientas funcionan realmente! Haces un video mostrando el resultado de las consultas propuestas y de tu modelo de ML entrenado!

<sub> **Spoiler**: El video NO DEBE durar mas de ***7 minutos*** y DEBE mostrar las consultas requeridas en funcionamiento desde la API** y una breve explicacion del modelo entrenado para el sistema de recomendacion. <sub/>

<br/>

<p align="center">
<img src="https://github.com/HX-PRomero/PI_ML_OPS/raw/main/src/MVP_MLops.PNG"  height=250>
</p>


## **Fuente de datos**

+ [Dataset](https://drive.google.com/drive/folders/1b49OVFJpjPPA1noRBBi1hSmMThXmNzxn): La carpeta 'ratings' tiene varios archivos con las rese√±as de los usuarios, la carpeta ra√≠z tiene un dataset por proveedor de servicios de streaming.
<br/>

## **Material de apoyo**

En este mismo repositorio podras encontrar algunos [links de ayuda](hhttps://github.com/HX-PRomero/PI_ML_OPS/raw/main/Material%20de%20apoyo.md). Recuerda que no son los unicos recursos que puedes utilizar!



  
<br/>

## **Deadlines importantes**

+ Apertura de formularios de entrega de proyectos: **Lunes 17, 10:00 hs gmt -3**

+ Cierre de formularios de entrega de proyectos: **Martes 18, 16:00hs gmt-3**
  
+ Demo: **Martes 18, 16:00hs gmt-3** 
